---
title: "Exploring the Key Factors That Drive Success in the Video Game Industry"
author: 
  - Sakhil Goel
thanks: "Code and data are available at: https://github.com/Sakhil-Goel/Game-Success.git."
date: today
date-format: long
abstract: "First sentence. Second sentence. Third sentence. Fourth sentence."
format: pdf
number-sections: true
toc: true
bibliography: references.bib
---

```{r}
#| include: false
#| warning: false
#| message: false

library(readr)
library(lubridate)
library(tidyverse)
library(dplyr)
library(tidyr)
library(knitr)
library(janitor)
library(scales)
library(RColorBrewer)
library(ggplot2)
library(kableExtra)
library(here)
library(arrow)
library(rstanarm)
library(modelsummary)

game_data <- read_parquet(here::here("data/analysis_data/cleaned_game_data.parquet"))
```


# Introduction

You can and should cross-reference sections and sub-sections. We use @citeR and @rohan.

The remainder of this paper is structured as follows. @sec-data....



# Data {#sec-data}

## Data Source
The primary dataset for this study was obtained from the RAWG Video Games Database API, which is an extensive repository of video game information. The RAWG API provides detailed data on video games, including their titles, genres, platforms, release dates, and user ratings such as Metacritic scores. Access to this data was facilitated through an API key obtained by registering on the RAWG.io website, which allowed for unrestricted access within the limits prescribed by the API guidelines.

## Variables and Selection Criteria
The variables selected for analysis were specifically chosen for their potential influence on a video game’s success. These include:

Name: The title of the video game.
Genres: The categories or genres assigned to the game (e.g., Action, Adventure).
Platforms: The gaming platforms on which each title is available (e.g., PC, Xbox).
Release Date: The official release date of the game.
Playtime: The average gameplay time reported by users.
Metacritic: The Metacritic score of the game, used as a proxy for critical success.
Each of these variables was deemed essential for analyzing the factors that could predict a video game's success, with the Metacritic score serving as the dependent variable in subsequent modeling.

## Data Collection Process
Data was collected via a scripted series of GET requests to the RAWG API. The requests were designed to paginate through the API's response, ensuring comprehensive data retrieval. Each request fetched data on 40 games per call—the maximum allowed by the API—with the script automatically handling pagination by incrementing the page number until all available data was downloaded.

## Data Cleaning and Preprocessing
Upon retrieval, the data underwent several preprocessing steps to ensure its suitability for analysis:

Cleaning: Data were cleaned to remove any entries with missing or incomplete information, particularly in the fields of Metacritic scores and release dates.
Transformation: Release dates were converted from string formats to date formats. Additionally, the 'genres' and 'platforms' fields, initially received as comma-separated strings, were transformed. For 'genres', each game was encoded into binary variables representing the presence or absence of each genre. For 'platforms', a count variable was created to indicate the number of platforms a game is available on.
New Variables: Two new variables were calculated:
num_genres: The total number of genres associated with each game.
num_platforms: The total number of platforms on which each game is available.

```{r}
#| label: table-cleaned-data-preview
#| tbl-cap: Preview of the cleaned Video Game Data
#| echo: false

game_data_preview <- head(game_data, 10)  # Preview the first 10 rows
kable(game_data_preview)
```

## Measurement
In this study, the primary indicator of video game success is represented by Metacritic scores, which aggregate critical reviews into a numerical score ranging from 0 to 100. These scores are considered interval data, where higher values indicate greater acclaim and are presumed to correlate with overall game success. This measurement is widely accepted within the industry as a reliable indicator of critical success and is used here to quantify the dependent variable in our analysis.

The variable "genres" is initially presented as a list of comma-separated values for each game, reflecting the multiple genres a game might belong to. To facilitate quantitative analysis, these genre labels are transformed into binary variables through a process known as one-hot encoding. Each genre is represented as a separate column in the dataset, with a value of 1 if the game is associated with that genre and 0 otherwise. This approach allows for the exploration of the impact of various genres on a game's success, accommodating the complex nature of genre classification in the gaming industry.

Another key variable, "platforms," is quantified by counting the number of platforms on which each game is available. This count is treated as a ratio variable, with the assumption that games available on more platforms have higher accessibility and potentially greater market penetration, which could influence their success. This variable is derived from a list of platform names provided for each game, reflecting its distribution scope.

The release date of each game is also captured and utilized in the analysis. For practical purposes and to align with the study's objectives of identifying trends, the exact release dates are converted into the release year. This transformation simplifies the data and aids in the examination of success trends over time, providing insights into how release timing within technological and market cycles might impact game popularity.

Throughout the data collection and preprocessing stages, rigorous checks ensure the consistency and reliability of the data. Variables such as Metacritic scores are particularly scrutinized due to their critical role in the analysis. The reliability of these scores is bolstered by their aggregated nature, which synthesizes diverse critical perspectives into a single metric. Conversely, variables that rely on user input, like playtimes, are treated with median values to mitigate bias. Prior to conducting any statistical analyses, the dataset undergoes validation to confirm that there are no missing values in key areas and that the distribution of numerical data meets the assumptions necessary for the chosen analytical methods.

This careful measurement and preprocessing of data ensure that the analysis conducted is both robust and reliable, providing meaningful insights into the factors that drive video game success.

```{r}
#| label: fig-metacritic-distribution
#| fig-cap: Distribution of Metacritic Scores
#| echo: false

# Ensure that 'metacritic' is a numeric column
game_data$metacritic <- as.numeric(game_data$metacritic)

ggplot(game_data, aes(x = metacritic)) +
  geom_histogram(bins = 30, fill = "blue", color = "black") +
  labs(title = "Distribution of Metacritic Scores", x = "Metacritic Score", y = "Frequency") +
  theme_minimal()
```

```{r}
#| label: fig-game-counts-platform
#| fig-cap: Count of Games by Platform
#| echo: false

# Assuming 'platforms' needs to be split and counted
game_data$released <- as.numeric(game_data$released)

ggplot(game_data, aes(x = released)) +
  geom_line() +
  geom_point() +
  labs(title = "Number of Games Released per Year",
       x = "Year",
       y = "Number of Games",
       caption = "Data sourced from RAWG Video Games Database API") +
  theme_minimal()
```

Talk way more about it. 



# Model

The goal of our modelling strategy is twofold. Firstly,...

Here we briefly describe the Bayesian analysis model used to investigate... Background details and diagnostics are included in [Appendix -@sec-model-details].

## Model set-up

Define $y_i$ as the number of seconds that the plane remained aloft. Then $\beta_i$ is the wing width and $\gamma_i$ is the wing length, both measured in millimeters.  

\begin{align} 
y_i|\mu_i, \sigma &\sim \mbox{Normal}(\mu_i, \sigma) \\
\mu_i &= \alpha + \beta_i + \gamma_i\\
\alpha &\sim \mbox{Normal}(0, 2.5) \\
\beta &\sim \mbox{Normal}(0, 2.5) \\
\gamma &\sim \mbox{Normal}(0, 2.5) \\
\sigma &\sim \mbox{Exponential}(1)
\end{align}

We run the model in R [@citeR] using the `rstanarm` package of @rstanarm. We use the default priors from `rstanarm`.


### Model justification

We expect a positive relationship between the size of the wings and time spent aloft. In particular...

We can use maths by including latex between dollar signs, for instance $\theta$.


# Results

Our results are summarized in @tbl-modelresults.

```{r}
#| echo: false
#| eval: true
#| warning: false
#| message: false

library(rstanarm)

first_model <-
  readRDS(file = here::here("models/first_model.rds"))
```

```{r}
#| echo: false
#| eval: true
#| label: tbl-modelresults
#| tbl-cap: "Explanatory models of flight time based on wing width and wing length"
#| warning: false

modelsummary::modelsummary(
  list(
    "First model" = first_model
  ),
  statistic = "mad",
  fmt = 2
)
```




# Discussion

## First discussion point {#sec-first-point}

If my paper were 10 pages, then should be be at least 2.5 pages. The discussion is a chance to show off what you know and what you learnt from all this. 

## Second discussion point

## Third discussion point

## Weaknesses and next steps

Weaknesses and next steps should also be included.

\newpage

\appendix

# Appendix {-}


# Additional data details

# Model details {#sec-model-details}

## Posterior predictive check

In @fig-ppcheckandposteriorvsprior-1 we implement a posterior predictive check. This shows...

In @fig-ppcheckandposteriorvsprior-2 we compare the posterior with the prior. This shows... 

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
#| label: fig-ppcheckandposteriorvsprior
#| layout-ncol: 2
#| fig-cap: "Examining how the model fits, and is affected by, the data"
#| fig-subcap: ["Posterior prediction check", "Comparing the posterior with the prior"]

#pp_check(first_model) +
 # theme_classic() +
  #theme(legend.position = "bottom")

#posterior_vs_prior(first_model) +
 # theme_minimal() +
  #scale_color_brewer(palette = "Set1") +
  #theme(legend.position = "bottom") +
  #coord_flip()
```

## Diagnostics

@fig-stanareyouokay-1 is a trace plot. It shows... This suggests...

@fig-stanareyouokay-2 is a Rhat plot. It shows... This suggests...

```{r}
#| echo: false
#| eval: true
#| message: false
#| warning: false
#| label: fig-stanareyouokay
#| fig-cap: "Checking the convergence of the MCMC algorithm"
#| fig-subcap: ["Trace plot", "Rhat plot"]
#| layout-ncol: 2

#plot(first_model, "trace")

#plot(first_model, "rhat")
```



\newpage


# References


